{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from QdrantU import QdrantU\n",
    "from Processing import TextEmbedder \n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "embedding_model = TextEmbedder()\n",
    "uploader = QdrantU(collection_name='News_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another parent, who asked not to be named, said her children had had good experiences at the school. “I was really shocked by the video. I was traumatised. I recognised where it happened and I just thought it could have been any of my sons,” she said. A number of parents said they knew it was not an isolated incident. Paul said his son had been racially abused by a different pupil at the school. “My son had trauma. He refused to come into the school. He was scared,” he said. “My son is a black belt but we teach him to keep calm, we teach him to be tolerant, to be loving. It took me a while to bring him back.” Cumbria police said the video that was being circulated was abhorrent and they have asked people to refrain from sharing it. Four teenage boys have been arrested, one on suspicion of racially aggravated actual bodily harm and the other three on suspicion of abetting racially aggravated actual bodily harm. All have been bailed with conditions and investigations are continuing. The force said: “We’d like to reassure the community we continue to take this incident extremely seriously. We understand an incident like this can be concerning for many and has caused shock to anyone viewing the images circulating online. Additional patrols have been deployed over the weekend and we will continue to engage with key community stakeholders.” The school has been approached for comment. Some outside the school discussed organising a march in solidarity. Kelvin Enabulele said he had been racially assaulted in Carlisle 16 years ago, so the reports brought back grim memories. “It’s happening in schools across Cumbria and the issue is how does the school handle it? What do they do about it?” he said. “We need to see things happening.”\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\n",
    "    \"What incident prompted the gathering of parents and supporters outside the school in Carlisle?\",\n",
    "    # \"How was the black pupil subjected to racial abuse, as described in the context?\",\n",
    "    # \"How does Sharon perceive the overall atmosphere in Carlisle in terms of racial tolerance?\",\n",
    "    # \"How did Nahida dismiss McGrath?\",\n",
    "    # \"What was the suggestion made by the keeper to Nahida?\",\n",
    "    # \"Describe the delivery that dismissed McGrath.\",\n",
    "    # \"What announcement are IMAX and Dolphin aiming to make soon?\",\n",
    "    # \"What is the significance of Amazon's involvement in 'The Blue Angels' release?\",\n",
    "    # \"According to O'Dowd, what will they seek out for all their documentary releases?\",\n",
    "    # \"Who is producing The Blue Angels?\",\n",
    "]\n",
    "\n",
    "ground_truth = [\n",
    "    \"The gathering of parents and supporters outside the school in Carlisle was prompted by a black pupil being subjected to abhorrent and distressing racial abuse.\",\n",
    "    # \"The black pupil was subjected to racial abuse through taunting, pushing, and punching by a white boy, who also made him kiss his shoes.\",\n",
    "    # \"Sharon perceives the overall atmosphere in Carlisle in terms of racial tolerance as generally friendly, but the recent incident has shaken her belief in the area's niceness and friendliness.\",\n",
    "    # \"Nahida dismissed McGrath with a classic left-arm spin delivery that teased outside off stump and then seared in at the stumps as an arm ball.\",\n",
    "    # \"The suggestion made by the keeper to Nahida was to bowl an arm ball, searing in at the stumps, faster and flatter.\",\n",
    "    # \"The delivery that dismissed McGrath was a classic left-arm spin, flighted and teased outside off stump, followed by an arm ball searing in at the stumps, faster and flatter.\",\n",
    "    # \"IMAX and Dolphin are aiming to announce their next project together very soon.\",\n",
    "    # \"The significance of Amazon's involvement in 'The Blue Angels' release is that they are partnering on the project, and the production team may seek out a streaming partner for all their documentary releases, although Amazon's involvement is not guaranteed for all projects.\",\n",
    "    # \"According to O'Dowd, they will seek out a streaming partner for all their documentary releases.\",\n",
    "    # \"The Blue Angels is being produced by Academy Award-winning producer Glen Zipper of Zipper Bros Films, Mark Monroe, JJ Abrams's Bad Robot Productions, and others.\"\n",
    "]\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in questions:\n",
    "    ScoredPoint = uploader.search(question, embedding_model,limit=1)[0]\n",
    "    contexts.append(ScoredPoint.payload['content'])\n",
    "    answers.append(llama(generate_prompt(question,contexts[-1])))\n",
    "    print(contexts[-1])\n",
    "    # sleep(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Split all the contexts into separate strings\n",
    "split_contexts = [context.split(\"\\n\\n\") for context in contexts]\n",
    "\n",
    "dataset = Dataset.from_dict({\"question\": questions, \"contexts\": split_contexts, \"answer\": answers, \"ground_truth\": ground_truth})\n",
    "\n",
    "print(type(split_contexts[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High faithfulness score: 0.5\n",
      "Low faithfulness score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_faithfulness(context, answer):\n",
    "    '''\n",
    "    input: context, answer\n",
    "    output: faithfulness score\n",
    "    this function calculates the faithfulness score of the answer given the context without using RAGAS\n",
    "    '''\n",
    "\n",
    "    answer_statements = answer.split(\".\")\n",
    "    supported_statements = sum(1 for statement in answer_statements if statement.strip() in context)\n",
    "    total_statements = len(answer_statements)\n",
    "    \n",
    "    if total_statements == 0:\n",
    "        return 0.0\n",
    "\n",
    "    faithfulness_score = supported_statements / total_statements\n",
    "\n",
    "    return faithfulness_score\n",
    "\n",
    "# Given context and generated answers\n",
    "context = \"Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time.\"\n",
    "generated_answer_high = \"Einstein was born in Germany on 14th March 1879.\"\n",
    "generated_answer_low = \"Einstein was born in Germany\"\n",
    "\n",
    "# Calculate faithfulness scores\n",
    "faithfulness_score_high = calculate_faithfulness(context, generated_answer_high)\n",
    "faithfulness_score_low = calculate_faithfulness(context, generated_answer_low)\n",
    "\n",
    "print(\"High faithfulness score:\", faithfulness_score_high)\n",
    "print(\"Low faithfulness score:\", faithfulness_score_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_answer_relevance(questions_answers, question, embedding_model=None):\n",
    "  \"\"\"\n",
    "  Calculates answer relevance score based on the Ragas paper's approach using a provided embedding model.\n",
    "\n",
    "  Args:\n",
    "      questions_answers: A list of dictionaries containing \"question\" and \"answer\" keys.\n",
    "      question: The original question as a string.\n",
    "      embedding_model: A TextEmbedder class instance for text embedding (optional).\n",
    "\n",
    "  Returns:\n",
    "      A float between 0 and 1 representing the answer relevance score,\n",
    "      or None if an error occurs.\n",
    "  \"\"\"\n",
    "\n",
    "  if not embedding_model:\n",
    "    print(\"Warning: No embedding model provided. Using cosine similarity without embedding.\")\n",
    "    return None  # Handle missing embedding model\n",
    "\n",
    "  # Create a TextEmbedder instance if not provided\n",
    "  embedder = embedding_model if isinstance(embedding_model, TextEmbedder) else TextEmbedder()\n",
    "\n",
    "  # Embed the original question\n",
    "  question_embedding = embedder.embed_query(question)\n",
    "\n",
    "  # Embed all answers\n",
    "  answer_embeddings = []\n",
    "  for qa in questions_answers:\n",
    "    answer = qa.get(\"answer\")\n",
    "    if answer:\n",
    "      answer_embedding = embedder.embed_text({\"content\": answer})[\"embedding\"]\n",
    "      answer_embeddings.append(answer_embedding)\n",
    "\n",
    "  # Calculate cosine similarity between original question and each answer\n",
    "  similarities = []\n",
    "  for answer_embedding in answer_embeddings:\n",
    "    similarity = sum(a * b for a, b in zip(question_embedding, answer_embedding)) / (\n",
    "        ((sum(a * a for a in question_embedding)) ** 0.5) * ((sum(b * b for b in answer_embedding)) ** 0.5)\n",
    "    )\n",
    "    similarities.append(similarity)\n",
    "\n",
    "  # Calculate answer relevance score (average similarity)\n",
    "  answer_relevance_score = sum(similarities) / len(similarities)\n",
    "\n",
    "  return answer_relevance_score\n",
    "\n",
    "# Example usage\n",
    "question = \"When was Albert Einstein born?\"\n",
    "questions_answers = [\n",
    "    {\"question\": \"What is the theory of relativity?\", \"answer\": \"The theory of relativity is ...\"},\n",
    "    {\"question\": \"Where was Albert Einstein born?\", \"answer\": \"Albert Einstein was born in Germany.\"},\n",
    "]\n",
    "\n",
    "# Assuming you have an instance of TextEmbedder class (e.g., embedder = TextEmbedder())\n",
    "answer_relevance_score = calculate_answer_relevance(questions_answers, question, embedder)\n",
    "\n",
    "if answer_relevance_score is not None:\n",
    "  print(\"Answer relevance score:\", answer_relevance_score)\n",
    "else:\n",
    "  print(\"Error calculating answer relevance score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScoredPoint(id='1b6ad5a0-4fb1-4fe7-9c90-f5c9fc06691d', version=345, score=0.737476, payload={'content': 'Italy won’t be pushovers in Parma, but anything other than a comfortable win for England will come as a surprise. It all kicks off at 2pm local time/3pm in the UK. Get in touch if you have a thought you want to share with the group. How do you reckon Mitchell will get on? How can he take this steamroller forward? Teams and updates to follow. ', 'publishdate': '2024-03-24T17:29:02Z', 'source': 'Guardian', 'title': 'Italy 0-48 England: Women’s Six Nations 2024 – as it happened '}, vector=None, shard_key=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nProvide a concise and informative response to the following question based on the provided context.\\n\\nContext:\\nItaly won’t be pushovers in Parma, but anything other than a comfortable win for England will come as a surprise. It all kicks off at 2pm local time/3pm in the UK. Get in touch if you have a thought you want to share with the group. How do you reckon Mitchell will get on? How can he take this steamroller forward? Teams and updates to follow. \\n\\nQuestion:\\nWhat announcement are IMAX and Dolphin aiming to make soon?\\n\\nResponse:\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What announcement are IMAX and Dolphin aiming to make soon?\"\n",
    "search_results = uploader.search(query, embedding_model,limit=1)\n",
    "print(search_results)\n",
    "context =ScoredPoint.payload['content']\n",
    "prompt = generate_prompt(context, query)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = llama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IMAX and Dolphin are aiming to make an announcement regarding Mitchell's performance and how he can continue to progress in the upcoming match. Stay tuned for updates on this development.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset \n",
    "# from ragas.metrics import faithfulness\n",
    "# from ragas import evaluate\n",
    "\n",
    "# data_samples = {\n",
    "#     'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
    "#     'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
    "#     'contexts' : [['The First AFL-NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'], \n",
    "#     ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],\n",
    "# }\n",
    "# dataset = Dataset.from_dict(data_samples)\n",
    "# score = evaluate(dataset,metrics=[faithfulness])\n",
    "# score.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
